{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Grid world example from:\n",
    "* https://github.com/jknthn/learning-rl/blob/master/dynamic-programming.ipynb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import matplotlib.pyplot as plt\n",
    "from IPython.display import clear_output\n",
    "from random import randint, random\n",
    "from time import sleep"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Utilities"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def print_board(agent_position):\n",
    "    fields = list(range(16))\n",
    "    board = \"-----------------\\n\"\n",
    "    for i in range(0, 16, 4):\n",
    "        line = fields[i:i+4]\n",
    "        for field in line:\n",
    "            if field == agent_position:\n",
    "                board += \"| A \"\n",
    "            elif field == fields[0] or field == fields[-1]:\n",
    "                board += \"| X \"\n",
    "            else:\n",
    "                board += \"|   \"\n",
    "        board += \"|\\n\"\n",
    "        board += \"-----------------\\n\"     \n",
    "    print(board)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print_board(8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_state_to_state_prime_verbose_map():\n",
    "    l = list(range(16))\n",
    "    state_to_state_prime = {}\n",
    "    for i in l:\n",
    "        if i == 0 or i == 15:\n",
    "            state_to_state_prime[i] = {'N': 0, 'E': 0, 'S': 0, 'W': 0}\n",
    "        elif i % 4 == 0:\n",
    "            state_to_state_prime[i] = {'N': i - 4 if i - 4 in l else i, 'E': i + 1 if i + 1 in l else i, 'S': i + 4 if i + 4 in l else i, 'W': i}\n",
    "        elif i % 4 == 3:\n",
    "            state_to_state_prime[i] = {'N': i - 4 if i - 4 in l else i, 'E': i, 'S': i + 4 if i + 4 in l else i, 'W': i - 1 if i - 1 in l else i}\n",
    "        else:\n",
    "            state_to_state_prime[i] = {'N': i - 4 if i - 4 in l else i, 'E': i + 1 if i + 1 in l else i, 'S': i + 4 if i + 4 in l else i, 'W': i - 1 if i - 1 in l else i}\n",
    "\n",
    "    return state_to_state_prime"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_random_policy():\n",
    "    return {i: {'N': 0.0, 'E': 0.0, 'S': 0.0, 'W': 0.0} if i == 0 or i == 15 else {'N': 0.25, 'E': 0.25, 'S': 0.25, 'W': 0.25} for i in range(16)} # [N, E, S, W]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_probability_map():\n",
    "    states = list(range(16))\n",
    "    state_to_state_prime = create_state_to_state_prime_verbose_map()\n",
    "    \n",
    "    probability_map = {}\n",
    "    \n",
    "    for state in states:\n",
    "        for move in [\"N\", \"E\", \"S\", \"W\"]:\n",
    "            for prime in states:\n",
    "                probability_map[(prime, -1, state, move)] = 0 if prime != state_to_state_prime[state][move] else 1\n",
    "            \n",
    "    return probability_map"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Agent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def agent(policy, starting_position=None, verbose=False):\n",
    "    l = list(range(16))\n",
    "    state_to_state_prime = create_state_to_state_prime_verbose_map()\n",
    "    agent_position = randint(1, 14) if starting_position is None else starting_position\n",
    "        \n",
    "    step_number = 1\n",
    "    action_taken = None\n",
    "    \n",
    "    if verbose:\n",
    "        print(\"Move: {} Position: {} Action: {}\".format(step_number, agent_position, action_taken))\n",
    "        print_board(agent_position)\n",
    "        print(\"\\n\")\n",
    "        sleep(2)\n",
    "    \n",
    "    while not (agent_position == 0 or agent_position == 15):\n",
    "        if verbose:\n",
    "            clear_output(wait=True)\n",
    "            print(\"Move: {} Position: {} Action: {}\".format(step_number, agent_position, action_taken))\n",
    "            print_board(agent_position)\n",
    "            print(\"\\n\")\n",
    "            sleep(1)\n",
    "        \n",
    "        current_policy = policy[agent_position]\n",
    "        next_move = random()\n",
    "        lower_bound = 0\n",
    "        for action, chance in current_policy.items():\n",
    "            if chance == 0:\n",
    "                continue\n",
    "            if lower_bound <= next_move < lower_bound + chance:\n",
    "                agent_position = state_to_state_prime[agent_position][action]\n",
    "                action_taken = action\n",
    "                break \n",
    "            lower_bound = lower_bound + chance\n",
    "                \n",
    "        step_number += 1   \n",
    "                \n",
    "    if verbose:\n",
    "        clear_output(wait=True)\n",
    "        print(\"Move: {} Position: {} Action: {}\".format(step_number, agent_position, action_taken))\n",
    "        print_board(agent_position)\n",
    "        print(\"Win!\")\n",
    "    \n",
    "    return step_number"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Random policy test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = []\n",
    "\n",
    "for i in range(1000):\n",
    "    clear_output(wait=True)\n",
    "    print(\"{}%\\n\".format((i + 1) / 10))\n",
    "    data.append(agent(create_random_policy()))\n",
    "    \n",
    "print(\"Average steps to finish: {}\".format(sum(data)/len(data)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "agent(create_random_policy(), verbose=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Create greedy policy based on V(s)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_greedy_policy(V_s):\n",
    "    s_to_sprime = create_state_to_state_prime_verbose_map()\n",
    "    policy = {}\n",
    "        \n",
    "    for state in range(16):\n",
    "        \n",
    "        state_values = {a: V_s[s_to_sprime[state][a]] for a in ['N', 'S', 'E', 'W']}\n",
    "        \n",
    "        if state == 0 or state == 15:\n",
    "            policy[state] = {'N': 0.0, 'E': 0.0, 'S': 0.0, 'W': 0.0}\n",
    "        else:\n",
    "            max_actions = [k for k, v in state_values.items() if v == max(state_values.values())]\n",
    "            policy[state] = {a: 1 / len(max_actions) if a in max_actions else 0.0 for a in ['N', 'S', 'E', 'W']}\n",
    "    return policy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Iterative policy evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def iterative_policy_evaluation(policy, theta=0.01, discount_rate=0.5):\n",
    "    V_s = {i: 0 for i in range(16)} # 1.\n",
    "    probablitiy_map = create_probability_map() # 2.\n",
    "\n",
    "    delta = 100 # 3.\n",
    "    while not delta < theta: # 4.\n",
    "        delta = 0 # 5.\n",
    "        for state in range(16): # 6.\n",
    "            v = V_s[state] # 7.\n",
    "            \n",
    "            total = 0 # 8.\n",
    "            for action in [\"N\", \"E\", \"S\", \"W\"]:\n",
    "                action_total = 0\n",
    "                for state_prime in range(16):\n",
    "                    action_total += probablitiy_map[(state_prime, -1, state, action)] * (-1 + discount_rate * V_s[state_prime])\n",
    "                total += policy[state][action] * action_total   \n",
    "                \n",
    "            V_s[state] = round(total, 1) # 9.\n",
    "            delta = max(delta, abs(v - V_s[state])) # 10.\n",
    "    return V_s # 11."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "policy = create_random_policy()\n",
    "V_s = iterative_policy_evaluation(policy)\n",
    "policy = create_greedy_policy(V_s)\n",
    "print(V_s)\n",
    "\n",
    "V_s = iterative_policy_evaluation(policy)\n",
    "policy = create_greedy_policy(V_s)\n",
    "print(V_s)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = []\n",
    "\n",
    "for i in range(1000):\n",
    "    clear_output(wait=True)\n",
    "    print(\"{}%\\n\".format((i + 1) / 10))\n",
    "    data.append(agent(policy))\n",
    "    \n",
    "print(\"Average steps to finish: {}\".format(sum(data)/len(data)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "agent(policy, verbose=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Value iteration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def value_iteration(V_s, theta=0.01, discount_rate=0.5):\n",
    "    probablitiy_map = create_probability_map()\n",
    "\n",
    "    delta = 100\n",
    "    while not delta < theta:\n",
    "        delta = 0\n",
    "        for state in range(1, 15):\n",
    "            v = V_s[state]\n",
    "            \n",
    "            totals = {}\n",
    "            for action in [\"N\", \"S\", \"E\", \"W\"]:\n",
    "                total = 0\n",
    "                for state_prime in range(16):\n",
    "                    total += probablitiy_map[(state_prime, -1, state, action)] * (-1 + discount_rate * V_s[state_prime])\n",
    "                totals[action] = total\n",
    "            \n",
    "            V_s[state] = round(max(totals.values()), 4)\n",
    "            delta = max(delta, abs(v - V_s[state]))\n",
    "    return V_s"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "V_s = {i: 0 for i in range(16)}\n",
    "V_s = value_iteration(V_s)\n",
    "policy = create_greedy_policy(V_s)\n",
    "\n",
    "print(V_s)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = []\n",
    "\n",
    "for i in range(1000):\n",
    "    clear_output(wait=True)\n",
    "    print(\"{}%\\n\".format((i + 1) / 10))\n",
    "    data.append(agent(policy))\n",
    "    \n",
    "print(\"Average steps to finish: {}\".format(sum(data)/len(data)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "agent(policy, verbose=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "create_state_to_state_prime_verbose_map()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "create_random_policy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(create_probability_map())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
